{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Data Exploration - SemEval 2026 Task 13\n",
    "\n",
    "**Goal:** Understand the dataset and find patterns in human vs AI-generated code\n",
    "\n",
    "**Level:** ‚≠ê Beginner (30-60 minutes)\n",
    "\n",
    "**What you'll learn:**\n",
    "- Load and explore parquet files\n",
    "- Calculate basic statistics\n",
    "- Create visualizations\n",
    "- Identify patterns in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded!\")\n",
    "print(f\"üîí Random seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_parquet('../data/train_A.parquet')\n",
    "val_df = pd.read_parquet('../data/validation_A.parquet')\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
    "\n",
    "# Show first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(f\"\\nBalance: {train_df['label'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 5))\n",
    "train_df['label'].value_counts().plot(kind='bar', color=['#66bb6a', '#ef5350'])\n",
    "plt.title('Class Distribution (0=Human, 1=AI)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Code Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add length features\n",
    "train_df['code_length'] = train_df['code'].str.len()\n",
    "train_df['num_lines'] = train_df['code'].str.count('\\n') + 1\n",
    "\n",
    "# Statistics by class\n",
    "print(\"Code Length Statistics:\")\n",
    "print(train_df.groupby('label')['code_length'].describe())\n",
    "print(\"\\nNumber of Lines Statistics:\")\n",
    "print(train_df.groupby('label')['num_lines'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Code length\n",
    "for label in [0, 1]:\n",
    "    data = train_df[train_df['label'] == label]['code_length']\n",
    "    axes[0].hist(data, bins=30, alpha=0.6, label=f'Label {label}')\n",
    "axes[0].set_xlabel('Code Length (characters)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Code Length Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Number of lines\n",
    "for label in [0, 1]:\n",
    "    data = train_df[train_df['label'] == label]['num_lines']\n",
    "    axes[1].hist(data, bins=30, alpha=0.6, label=f'Label {label}')\n",
    "axes[1].set_xlabel('Number of Lines')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Line Count Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Code Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example human code\n",
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE: Human-Written Code (Label 0)\")\n",
    "print(\"=\" * 60)\n",
    "human_sample = train_df[train_df['label'] == 0].iloc[0]['code']\n",
    "print(human_sample)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXAMPLE: AI-Generated Code (Label 1)\")\n",
    "print(\"=\" * 60)\n",
    "ai_sample = train_df[train_df['label'] == 1].iloc[0]['code']\n",
    "print(ai_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Your Turn! üéØ\n",
    "\n",
    "**Tasks to try:**\n",
    "1. Calculate average word length for human vs AI code\n",
    "2. Count frequency of common keywords (def, class, if, for)\n",
    "3. Analyze comment patterns (lines starting with #)\n",
    "4. Create more visualizations\n",
    "\n",
    "**Add your code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your exploration code here!\n",
    "def word_length():\n",
    "    '''\n",
    "    Calculate average word length for human vs AI code\n",
    "\n",
    "    Returns:  \n",
    "        tuple: (human_code, ai_code)  \n",
    "    '''\n",
    "    train_df['word_length'] = train_df['code'].str.split().str.len()\n",
    "    \n",
    "    human_code = train_df[train_df['label'] == 0]['word_length'].mean()\n",
    "    ai_code = train_df[train_df['label'] == 1]['word_length'].mean()\n",
    "    print(f\"Human code average word length: {human_code:.2f}\")\n",
    "    print(f\"AI code average word length: {ai_code:.2f}\")\n",
    "    \n",
    "    # Visualize distributions\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    for label in [0, 1]:\n",
    "        data = train_df[train_df['label'] == label]['word_length']\n",
    "        plt.hist(data, bins=30, alpha=0.6, label=f'Label {label}')\n",
    "    plt.xlabel('Word Count per Code Sample')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Word Count Distribution')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return human_code, ai_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings\n",
    "\n",
    "**Document your observations:**\n",
    "- What patterns did you notice?\n",
    "- Are there clear differences between human and AI code?\n",
    "- What features might be useful for classification?\n",
    "\n",
    "**Your notes:**\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Next Steps\n",
    "\n",
    "1. **Share your findings** - Open a PR with this notebook\n",
    "2. **Try notebook 02** - Feature analysis\n",
    "3. **Propose new features** - Based on what you discovered\n",
    "\n",
    "**Great job exploring the data!** üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
