{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Baseline Model Training - SemEval 2026 Task 13\n",
    "\n",
    "**Goal:** Train and compare baseline ML models\n",
    "\n",
    "**Level:** ‚≠ê‚≠ê Intermediate (1-2 hours)\n",
    "\n",
    "**What you'll learn:**\n",
    "- Feature extraction from code\n",
    "- Train multiple ML models\n",
    "- Compare model performance\n",
    "- Understand baseline results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.features import extract_features_from_dataframe\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded!\")\n",
    "print(f\"üîí Random seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.features import extract_features_from_dataframe\n",
    "\n",
    "print(\"‚úÖ Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_parquet('../data/train_A.parquet')\n",
    "val_df = pd.read_parquet('../data/validation_A.parquet')\n",
    "\n",
    "print(f\"Training: {len(train_df)} samples\")\n",
    "print(f\"Validation: {len(val_df)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "print(\"Extracting features...\")\n",
    "X_train = extract_features_from_dataframe(train_df)\n",
    "X_val = extract_features_from_dataframe(val_df)\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "print(f\"Feature shape: {X_train.shape}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "print(f\"\\nFeature names: {list(X_train.columns)[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_f1 = f1_score(y_train, y_pred_train, average='macro')\n",
    "    val_f1 = f1_score(y_val, y_pred_val, average='macro')\n",
    "    \n",
    "    results[name] = {\n",
    "        'train_f1': train_f1,\n",
    "        'val_f1': val_f1,\n",
    "        'model': model,\n",
    "        'predictions': y_pred_val\n",
    "    }\n",
    "    \n",
    "    print(f\"Train F1: {train_f1:.4f}\")\n",
    "    print(f\"Val F1:   {val_f1:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_pred_val, target_names=['Human', 'AI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Train F1': [r['train_f1'] for r in results.values()],\n",
    "    'Val F1': [r['val_f1'] for r in results.values()]\n",
    "})\n",
    "\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, comparison_df['Train F1'], width, label='Train F1', color='#66bb6a')\n",
    "ax.bar(x + width/2, comparison_df['Val F1'], width, label='Val F1', color='#42a5f5')\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=12)\n",
    "ax.set_ylabel('Macro F1 Score', fontsize=12)\n",
    "ax.set_title('Model Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df['Model'], rotation=15, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrix (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model_name = max(results, key=lambda k: results[k]['val_f1'])\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Validation F1: {results[best_model_name]['val_f1']:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val, best_predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Human', 'AI'],\n",
    "            yticklabels=['Human', 'AI'])\n",
    "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "rf_model = results['Random Forest']['model']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='#66bb6a')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Top 15 Most Important Features', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Your Turn! üéØ\n",
    "\n",
    "**Experiments to try:**\n",
    "1. Tune hyperparameters (max_depth, n_estimators, etc.)\n",
    "2. Try other models (SVM, XGBoost, LightGBM)\n",
    "3. Feature selection (remove low-importance features)\n",
    "4. Cross-validation for more robust evaluation\n",
    "\n",
    "**Add your code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiments here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "**Expected baseline performance:**\n",
    "- Logistic Regression: ~50-55% F1\n",
    "- Random Forest: ~55-60% F1\n",
    "- Gradient Boosting: ~58-62% F1\n",
    "\n",
    "**To reach competitive performance (85-95% F1):**\n",
    "- Add AST features (notebook 03)\n",
    "- Use transformer models like CodeBERT (notebook 05)\n",
    "- Ensemble multiple models\n",
    "\n",
    "**Your observations:**\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Next Steps\n",
    "\n",
    "1. **Try hyperparameter tuning** - Can you beat the baseline?\n",
    "2. **Move to notebook 03** - Add AST features for +10-15% F1\n",
    "3. **Share your results** - Open a PR with your experiments\n",
    "\n",
    "**Great work on training baseline models!** üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
