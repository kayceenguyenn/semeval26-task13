{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ó Task B: CodeBERT Fine-Tuning - SemEval 2026 Task 13\n",
        "\n",
        "**Goal:** Fine-tune a CodeBERT model to perform 11-class model attribution (Task B).\n",
        "\n",
        "**What you'll learn:**\n",
        "- How to load Task B data into a HuggingFace `Dataset`\n",
        "- How to tokenize code with CodeBERT\n",
        "- How to fine-tune a transformer with the `Trainer` API\n",
        "- How to evaluate macro F1 on the validation set\n",
        "\n",
        "> This notebook is intentionally lightweight and mirrors the style of `02_baseline_training.ipynb` and `03_task_b_training.ipynb`. Run cells top-to-bottom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "‚úÖ Libraries loaded!\n",
            "üîí Random seed: 42\n"
          ]
        }
      ],
      "source": [
        "# 1. Setup\n",
        "\n",
        "# Pin modern versions so `TrainingArguments` supports `evaluation_strategy`\n",
        "%pip install -q -U \"transformers>=4.40.0\" \"datasets>=2.19.0\" \"accelerate>=0.26.0\" \"evaluate>=0.4.1\" scikit-learn\n",
        "\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "import evaluate\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "print(\"‚úÖ Libraries loaded!\")\n",
        "print(f\"üîí Random seed: {SEED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö° QUICK TEST MODE: Using subset of data\n",
            "   Training: 44,394 samples (stratified)\n",
            "   Validation: 6,710 samples (stratified)\n",
            "Training samples: 44,394\n",
            "Validation samples: 6,710\n",
            "Columns: ['code', 'generator', 'label', 'language']\n",
            "Num labels: 11\n"
          ]
        }
      ],
      "source": [
        "# 2. Load Task B Data\n",
        "\n",
        "train_df = pd.read_parquet('../data/train_B.parquet')\n",
        "val_df   = pd.read_parquet('../data/validation_B.parquet')\n",
        "\n",
        "# QUICK TEST MODE: Set to True for fast testing (~30-60 min instead of 12-24 hours)\n",
        "QUICK_TEST = True  # Change to False for full training\n",
        "\n",
        "if QUICK_TEST:\n",
        "    # Use stratified sample to maintain class distribution\n",
        "    train_df = train_df.groupby('label', group_keys=False).apply(\n",
        "        lambda x: x.sample(min(5000, len(x)), random_state=SEED)\n",
        "    ).reset_index(drop=True)\n",
        "    val_df = val_df.groupby('label', group_keys=False).apply(\n",
        "        lambda x: x.sample(min(1000, len(x)), random_state=SEED)\n",
        "    ).reset_index(drop=True)\n",
        "    print(\"‚ö° QUICK TEST MODE: Using subset of data\")\n",
        "    print(f\"   Training: {len(train_df):,} samples (stratified)\")\n",
        "    print(f\"   Validation: {len(val_df):,} samples (stratified)\")\n",
        "\n",
        "print(f\"Training samples: {len(train_df):,}\")\n",
        "print(f\"Validation samples: {len(val_df):,}\")\n",
        "print(f\"Columns: {list(train_df.columns)}\")\n",
        "\n",
        "num_labels = train_df['label'].nunique()\n",
        "print(f\"Num labels: {num_labels}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fb600a3e21b43a188815814d55b0a3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/44394 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb2ec89947df444083553d56ce7e668c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6710 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['labels', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 44394\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# 3. Prepare HuggingFace Datasets and Tokenizer\n",
        "\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Wrap pandas DataFrames into HuggingFace Datasets\n",
        "train_ds = Dataset.from_pandas(train_df[['code', 'label']])\n",
        "val_ds   = Dataset.from_pandas(val_df[['code', 'label']])\n",
        "\n",
        "max_length = 128  # Reduced for 8GB unified memory (can try 192 if stable)\n",
        "\n",
        "def preprocess_fn(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"code\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "    )\n",
        "\n",
        "train_ds_tok = train_ds.map(preprocess_fn, batched=True, remove_columns=[\"code\"])\n",
        "val_ds_tok   = val_ds.map(preprocess_fn,   batched=True, remove_columns=[\"code\"])\n",
        "\n",
        "train_ds_tok = train_ds_tok.rename_column(\"label\", \"labels\")\n",
        "val_ds_tok   = val_ds_tok.rename_column(\"label\", \"labels\")\n",
        "\n",
        "train_ds_tok.set_format(\"torch\")\n",
        "val_ds_tok.set_format(\"torch\")\n",
        "\n",
        "print(train_ds_tok)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model initialized for 11 classes\n"
          ]
        }
      ],
      "source": [
        "# 4. Initialize CodeBERT Model for 11-Class Classification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "\n",
        "metric_f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    macro_f1 = metric_f1.compute(predictions=preds, references=labels, average=\"macro\")\n",
        "    return {\"macro_f1\": macro_f1[\"f1\"]}\n",
        "\n",
        "print(\"‚úÖ Model initialized for\", num_labels, \"classes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö° QUICK TEST MODE: Training for 1 epoch (~30-60 min)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/59/5z57bq1n0w5bw5q_qbtjn7p00000gn/T/ipykernel_6916/1361865181.py:46: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5550' max='5550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5550/5550 1:38:32, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.601600</td>\n",
              "      <td>1.552924</td>\n",
              "      <td>0.394201</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1678' max='1678' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1678/1678 02:22]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Validation metrics:\n",
            "{'eval_loss': 1.552924394607544, 'eval_macro_f1': 0.3942011021447564, 'eval_runtime': 142.8855, 'eval_samples_per_second': 46.961, 'eval_steps_per_second': 11.744, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "# 5. Training Configuration and Fine-Tuning (Optimized for 8GB Unified Memory)\n",
        "\n",
        "# Check if QUICK_TEST is defined (from cell 2)\n",
        "try:\n",
        "    is_quick_test = QUICK_TEST\n",
        "except NameError:\n",
        "    is_quick_test = False\n",
        "\n",
        "batch_size = 2  # Reduced for 8GB unified memory\n",
        "gradient_accumulation_steps = 4  # Simulates batch_size=8 (2*4)\n",
        "effective_batch_size = batch_size * gradient_accumulation_steps\n",
        "\n",
        "# Adjust epochs and logging for quick test\n",
        "num_epochs = 1 if is_quick_test else 3\n",
        "logging_steps = 50 if is_quick_test else 500\n",
        "\n",
        "if is_quick_test:\n",
        "    print(\"‚ö° QUICK TEST MODE: Training for 1 epoch (~30-60 min)\")\n",
        "else:\n",
        "    print(\"üöÄ FULL TRAINING MODE: Training for 3 epochs (~12-24 hours)\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./codebert_taskB\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=logging_steps,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=4,  # Reduced eval batch size\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    num_train_epochs=num_epochs,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    greater_is_better=True,\n",
        "    # Memory optimizations\n",
        "    fp16=False,  # Use bf16 on Apple Silicon instead\n",
        "    bf16=torch.backends.mps.is_available(),  # Mixed precision for Apple Silicon\n",
        "    dataloader_pin_memory=False,  # Disable for unified memory\n",
        "    dataloader_num_workers=0,  # Reduce memory overhead\n",
        "    gradient_checkpointing=True,  # Trade compute for memory\n",
        "    max_grad_norm=1.0,  # Gradient clipping\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds_tok,\n",
        "    eval_dataset=val_ds_tok,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "metrics = trainer.evaluate()\n",
        "print(\"\\nüìä Validation metrics:\")\n",
        "print(metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Improvements Made:\n",
        "\n",
        "1. **Language prefix**: Added `[LANG=...]` prefix to code to help model distinguish languages\n",
        "2. **Increased max_length**: 128 ‚Üí 192 (captures more context)\n",
        "3. **More epochs**: 1 ‚Üí 2 (quick test), 3 ‚Üí 5 (full training)\n",
        "4. **Learning rate scheduling**: Added warmup (10%) + cosine decay\n",
        "5. **Lower learning rate**: 5e-5 ‚Üí 3e-5 (more stable training)\n",
        "6. **Better metrics**: Added per-class F1 for diagnostics\n",
        "7. **Checkpoint management**: Keep only best 3 checkpoints\n",
        "\n",
        "**Expected improvement**: F1 should increase from ~0.39 to **0.50-0.65** with these changes.\n",
        "\n",
        "---\n",
        "\n",
        "## About \"Features\" for Transformers\n",
        "\n",
        "**Short answer:** Traditional feature engineering (AST, keyword counts, etc.) doesn't directly help transformers, but you CAN add contextual information as text.\n",
        "\n",
        "**For Transformers (CodeBERT):**\n",
        "- ‚úÖ **Add context as text prefixes**: Language, code length buckets, complexity hints\n",
        "- ‚úÖ **Metadata as text**: `[LANG=python]`, `[LENGTH=medium]`, `[COMPLEXITY=high]`\n",
        "- ‚ùå **Traditional numeric features**: AST depth, keyword counts (these need separate models)\n",
        "\n",
        "**For Traditional ML (XGBoost, etc.):**\n",
        "- ‚úÖ **All feature types work**: AST, keywords, statistics, etc.\n",
        "- ‚úÖ **Feature engineering is crucial**: Can significantly boost F1\n",
        "\n",
        "**Best approach for Task B:**\n",
        "1. **Transformer**: Add more text context (see cell 3a below)\n",
        "2. **Hyperparameter tuning**: Most impactful (see cell 6 below)\n",
        "3. **Ensemble**: Combine transformer + traditional ML models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Hyperparameter Tuning (Optional but Recommended)\n",
        "\n",
        "**When to use:** After you've run the baseline training and want to improve F1 further.\n",
        "\n",
        "**Strategy:** Test different hyperparameter combinations and pick the best one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
